# A/B Test Results Analysis

# Evaluating User Conversion Outcomes for an E-Commerce Website

**Project Overview:**

This project analyzes the results of an A/B test conducted by an e-commerce company that aimed to increase customer conversions through a redesigned landing page. The business question is straightforward:

Should the company implement the new page, keep the old one, or continue running the experiment?

To answer this, we apply statistical analysis, probability testing, and practical decision-making frameworks commonly used in product analytics and growth experimentation.

**Objectives:**
	•	Assess the effectiveness of the new landing page vs. the old page.
	•	Determine whether any observed difference in conversion rates is statistically significant.
	•	Provide a recommendation backed by data:
	•	Adopt the new page
	•	Retain the old page
	•	Run the experiment longer

**Key Steps in the Analysis:**

**1. Data Exploration**
	•	Inspect dataset structure
	•	Validate experiment randomization
	•	Check for inconsistencies or sampling issues

**2. Probability & Statistical Tests**
	•	Compute conversion rates for both groups
	•	Perform hypothesis testing, typically:
	•	Z-test for difference in proportions
	•	Confidence interval estimation
	•	Examine p-values and statistical significance

**3. Practical & Business Interpretation**
	•	Assess whether the statistical results translate into real business value
	•	Consider effect size, risk, and uncertainty
	•	Recommend final action to stakeholders

**4. Tools & Technologies**
	•	Python (Pandas, NumPy, SciPy)
	•	Statistical Testing (Z-tests, bootstrapping, probability modeling)
	•	Data Visualization (Matplotlib, Seaborn)
	•	Jupyter Notebook

This project delivers:
	•	A clear comparison of conversion performance between the A and B groups
	•	Evidence-based conclusions about the impact of the new design
	•	Actionable recommendations grounded in statistical rigor
